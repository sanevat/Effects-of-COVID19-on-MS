{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Reading data into a DataFrame\n",
    "df = pd.read_csv('GDSI_OpenDataset_Final.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e4194496c48d19d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Applying imputation \n",
    "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "categorical_encoded = encoder.fit_transform(df[categorical_cols])\n",
    "\n",
    "encoded_features = encoder.get_feature_names_out(categorical_cols)\n",
    "encoded_df = pd.DataFrame(categorical_encoded, columns=encoded_features)\n",
    "\n",
    "# Combine the numeric and encoded categorical data \n",
    "cleaned_df = pd.concat([df[numeric_cols], encoded_df], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daa654a778003a3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cleaned_df)\n",
    "\n",
    "pca = PCA(n_components=0.95)  # retain 95% of the variance \n",
    "principal_components = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Create a DataFrame for the principal components \n",
    "pca_df = pd.DataFrame(data=principal_components, columns=[f\"PC{i + 1}\" for i in range(principal_components.shape[1])])\n",
    "\n",
    "original_target = df['covid19_outcome_recovered']\n",
    "filtered_target = original_target[original_target != 'not_applicable']\n",
    "encoded_target = (filtered_target == 'yes').astype(int)\n",
    "\n",
    "# Match the indices of the PCA DataFrame \n",
    "filtered_pca_df = pca_df.loc[filtered_target.index]\n",
    "\n",
    "# Split the data into training and testing sets \n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    filtered_pca_df, encoded_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train_filtered, y_train_filtered)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad0ca6f59cdc4d7f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Apply SMOTE for handling imbalanced classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define models and parameter grids for hyperparameter tuning\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network (MLPClassifier)\": MLPClassifier(max_iter=1000, early_stopping=True, validation_fraction=0.1),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss'),\n",
    "    \"LightGBM\": lgb.LGBMClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {'C': [0.01, 0.1, 1, 10, 100], 'solver': ['liblinear', 'saga']},\n",
    "    \"Random Forest\": {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]},\n",
    "    \"Support Vector Machine\": {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    \"K-Nearest Neighbors\": {'n_neighbors': [3, 5, 7]},\n",
    "    \"Neural Network (MLPClassifier)\": {'hidden_layer_sizes': [(50,), (100,), (100, 50)]},\n",
    "    \"XGBoost\": {'n_estimators': [50, 100, 200]},\n",
    "    \"LightGBM\": {'num_leaves': [31, 63, 127]}\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "for model_name, param_grid in param_grids.items():\n",
    "    model = models[model_name]\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validated score: {grid_search.best_score_:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecf6ab7838b35b6c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "for model_name, model in models.items():\n",
    "    # Train model on balanced training set\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "    y_pred = model.predict(X_test_filtered)\n",
    "\n",
    "    # Accuracy and classification report\n",
    "    accuracy = accuracy_score(y_test_filtered, y_pred)\n",
    "    class_report = classification_report(y_test_filtered, y_pred)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test_filtered, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test_filtered)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test_filtered, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'r--')\n",
    "        plt.title(f'ROC Curve for {model_name}')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1419f9f020219e7e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up the number of rows and columns based on the number of models\n",
    "num_models = len(models)\n",
    "fig, axes = plt.subplots(num_models, 1, figsize=(8, 4 * num_models))\n",
    "\n",
    "# Loop over models and axes\n",
    "for ax, (model_name, model) in zip(axes, models.items()):\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test_filtered, y_test_filtered)\n",
    "\n",
    "    print(f\"{model_name} - Training Accuracy: {train_accuracy:.2f}, Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Calculate learning curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X_train, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "\n",
    "    train_scores_mean = train_scores.mean(axis=1)\n",
    "    test_scores_mean = test_scores.mean(axis=1)\n",
    "\n",
    "    # Plot learning curve for the current model in the corresponding subplot\n",
    "    ax.plot(train_sizes, train_scores_mean, label=\"Training score\")\n",
    "    ax.plot(train_sizes, test_scores_mean, '--', label=\"Validation score\")\n",
    "    ax.set_title(f'Learning Curve for {model_name}')\n",
    "    ax.set_xlabel('Training Sizes')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the combined image with all subplots\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b47b756c8044cdd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a list to store model predictions and probabilities\n",
    "results = []\n",
    "\n",
    "# Iterate through the models and store results\n",
    "for model_name, model in models.items():\n",
    "    #predicted_outcome = model.predict(new_data_point_df)\n",
    "    #predicted_probability = model.predict_proba(new_data_point_df)\n",
    "    \n",
    "    outcome_mapping = {0: \"no\", 1: \"yes\"}\n",
    "    #predicted_outcome_str = outcome_mapping[predicted_outcome[0]]\n",
    "    \n",
    "    # Append the results to the list (model name, predicted outcome, and probabilities)\n",
    "    #results.append({\n",
    "        #\"Model\": model_name,\n",
    "       # \"Predicted Outcome\": predicted_outcome_str,\n",
    "       # \"Probability (no)\": predicted_probability[0][0],\n",
    "       # \"Probability (yes)\": predicted_probability[0][1]\n",
    "    #})\n",
    "\n",
    "#results_df = pd.DataFrame(results)\n",
    "\n",
    "# Format the probabilities to 3 decimal places for better readability\n",
    "#results_df['Probability (no)'] = results_df['Probability (no)'].round(3)\n",
    "#results_df['Probability (yes)'] = results_df['Probability (yes)'].round(3)\n",
    "\n",
    "# Display the table\n",
    "#print(results_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "340655c9e81fe486",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate fairness across demographic groups\n",
    "def evaluate_fairness(y_true, y_pred, demographic_col):\n",
    "    # Convert inputs to Series if they are numpy arrays\n",
    "    if isinstance(y_true, np.ndarray):\n",
    "        y_true = pd.Series(y_true, index=demographic_col.index)\n",
    "    if isinstance(y_pred, np.ndarray):\n",
    "        y_pred = pd.Series(y_pred, index=demographic_col.index)\n",
    "\n",
    "    demographic_groups = demographic_col.unique()\n",
    "    results = {}\n",
    "\n",
    "    for group in demographic_groups:\n",
    "        # Create a mask for the current demographic group\n",
    "        group_mask = demographic_col == group\n",
    "        \n",
    "        # Extract true and predicted values for this group using the mask\n",
    "        group_y_true = y_true[group_mask]\n",
    "        group_y_pred = y_pred[group_mask]\n",
    "\n",
    "        # Debugging statements\n",
    "        print(f\"Evaluating group: {group}\")\n",
    "        print(f\"Group y_true: {group_y_true}\")\n",
    "        print(f\"Group y_pred: {group_y_pred}\")\n",
    "\n",
    "        # Check if both arrays have values to avoid empty group error\n",
    "        if not group_y_true.empty and not group_y_pred.empty:\n",
    "            # Calculate the metrics\n",
    "            accuracy = accuracy_score(group_y_true, group_y_pred)\n",
    "            precision = precision_score(group_y_true, group_y_pred, zero_division=0)\n",
    "            recall = recall_score(group_y_true, group_y_pred, zero_division=0)\n",
    "            f1 = f1_score(group_y_true, group_y_pred, zero_division=0)\n",
    "\n",
    "            # Store the results\n",
    "            results[group] = {\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data for group: {group}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Assuming you have your predictions (y_pred) and true labels (y_true)\n",
    "y_pred_filtered = model.predict(X_test_filtered)  # For example, using your chosen model\n",
    "\n",
    "# Convert predictions to a DataFrame or Series if needed\n",
    "y_pred_filtered = pd.Series(y_pred_filtered, index=y_test_filtered.index)\n",
    "\n",
    "# Evaluate fairness\n",
    "fairness_results = evaluate_fairness(y_test_filtered, y_pred_filtered, df['age_category'])\n",
    "for category, metrics in fairness_results.items():\n",
    "    print(f\"Age Category {category}: {metrics}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10081de96503ebd1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate fairness across demographic groups\n",
    "def evaluate_fairness(y_true, y_pred, demographic_col):\n",
    "    # Convert inputs to Series if they are numpy arrays\n",
    "    if isinstance(y_true, np.ndarray):\n",
    "        y_true = pd.Series(y_true, index=demographic_col.index)\n",
    "    if isinstance(y_pred, np.ndarray):\n",
    "        y_pred = pd.Series(y_pred, index=demographic_col.index)\n",
    "\n",
    "    demographic_groups = demographic_col.unique()\n",
    "    results = {}\n",
    "\n",
    "    for group in demographic_groups:\n",
    "        # Create a mask for the current demographic group\n",
    "        group_mask = demographic_col == group\n",
    "        \n",
    "        # Extract true and predicted values for this group using the mask\n",
    "        group_y_true = y_true[group_mask]\n",
    "        group_y_pred = y_pred[group_mask]\n",
    "\n",
    "        # Check if both arrays have values to avoid empty group error\n",
    "        if not group_y_true.empty and not group_y_pred.empty:\n",
    "            # Calculate the metrics\n",
    "            accuracy = accuracy_score(group_y_true, group_y_pred)\n",
    "            precision = precision_score(group_y_true, group_y_pred, zero_division=0)\n",
    "            recall = recall_score(group_y_true, group_y_pred, zero_division=0)\n",
    "            f1 = f1_score(group_y_true, group_y_pred, zero_division=0)\n",
    "\n",
    "            # Store the results\n",
    "            results[group] = {\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data for group: {group}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# List of demographic columns to evaluate\n",
    "demographic_columns = ['age_in_cat', 'bmi_in_cat2', 'sex', 'has_comorbidities']  # Add more as needed\n",
    "\n",
    "# Assuming you have your predictions (y_pred) and true labels (y_true)\n",
    "y_pred_filtered = model.predict(X_test_filtered)  # Example model prediction\n",
    "y_pred_filtered = pd.Series(y_pred_filtered, index=y_test_filtered.index)\n",
    "\n",
    "# Loop through each demographic column and evaluate fairness\n",
    "for demographic_col in demographic_columns:\n",
    "    fairness_results = evaluate_fairness(y_test_filtered, y_pred_filtered, df[demographic_col])\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(fairness_results).T  # Transpose to have groups as rows\n",
    "    results_df.reset_index(inplace=True)  # Reset index to have group names as a column\n",
    "    results_df.rename(columns={'index': demographic_col}, inplace=True)\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    results_df.set_index(demographic_col).plot(kind='bar', ax=plt.gca())\n",
    "    plt.title(f'Model Performance Metrics by {demographic_col.capitalize()}')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9244c60e4d027646",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7fe58b3a35dca314",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8414f78e4e335f06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
